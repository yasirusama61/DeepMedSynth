## ğŸ“… Update: April 25, 2025 â€” U-Net Segmentation Stability & Overfitting Fixes

### âœ¨ Key Improvements

- ğŸ”§ **Added Dropout and BatchNorm** to all U-Net convolutional blocks to improve feature generalization and reduce memorization.

- ğŸ§  **Reduced Batch Size** from `64 â†’ 16` to increase update frequency and mitigate overfitting on small slice-wise batches.

- ğŸ§ª **Upgraded Data Augmentation** using **Albumentations** for spatially-aware transforms:
  - Horizontal flip
  - Shift/scale/rotate
  - Random brightness/contrast

- ğŸ“‰ **Loss Function Tweaks**:
  - Continued with **ComboLoss** (`0.5 Ã— BCE + 0.5 Ã— Dice`)
  - Smoothed hard 0/1 masks with clipping to stabilize early epochs

- ğŸ“ **Replaced Accuracy with Dice Coefficient** as the primary metric for segmentation performance.

- ğŸ“ˆ **Visualization Improvements**:
  - Loss curves (train, val)
  - Dice coefficient curves (train, val)

- ğŸ” **Training Strategy Enhanced**:
  - Added `EarlyStopping` with `patience = 10`
  - Added `ReduceLROnPlateau` to dynamically lower learning rate if validation loss plateaus


## ğŸ“ˆ Final Training Results (Early Stopping at Epoch 20)

- âœ… Training automatically stopped after epoch **20** due to plateau in validation loss.
- ğŸ“‰ **Final Loss Values**:
  - Train Loss: ~0.425
  - Val Loss: ~0.430

- ğŸ“ˆ **Final Dice Coefficient**:
  - Train Dice: ~0.23
  - Val Dice: ~0.22

- ğŸ“Š Visualizations:
  ![Loss Plot](segmentation_results/loss_plot.png)
  ![Dice Plot](segmentation_results/dice_plot.png)

# ğŸ“ CHANGELOG

## ğŸ“… [April 26, 2025] - Final Model and Training Strategy Updates

### ğŸ§  Final Model Architecture Changes
- âœ… 2D U-Net Backbone (input: 128Ã—128, single-channel Flair slices)
- âœ… Dropout (rate = 0.2) after each convolutional block to prevent overfitting
- âœ… Batch Normalization after each convolutional block
- âœ… Output Activation: Sigmoid for binary mask prediction
- âœ… Loss Function: ComboLoss (0.5 Ã— Binary Crossentropy + 0.5 Ã— Dice Loss)
- âœ… Evaluation Metric: Dice Coefficient
- âœ… Single output channel for whole tumor segmentation

---

### ğŸ› ï¸ Training Strategy Improvements
- ğŸ”½ Reduced Batch Size: from 64 â†’ 16
- ğŸ§ª Data Augmentation via Albumentations:
  - Horizontal flip
  - Shift-Scale-Rotate
  - Random brightness/contrast
- ğŸ” EarlyStopping (patience = 20) on validation loss to prevent overfitting
- ğŸ“‰ ReduceLROnPlateau (patience = 5) with LR decay factor 0.5
- ğŸ”„ Resumed training from checkpoint after early stopping triggered
- ğŸ“ˆ Completed full training to 100 epochs

---

### ğŸ“ˆ Final Evaluation Metrics
- **Training Loss**: ~0.425
- **Validation Loss**: ~0.430
- **Test Loss**: ~0.4154
- **Test Dice Coefficient**: ~0.2596
